{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Only if you have \n",
    "import torch\n",
    "print(\"CUDA Availability: \")\n",
    "print(torch.cuda.is_available())  # Returns True if CUDA is available: GPU is available && CUDA is installed and configured\n",
    "print(torch.cuda.get_device_name(0))  # Returns GPU name if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for audio and transcripts\n",
    "AUDIO_DIR = \"audio_files\"\n",
    "TRANSCRIPT_DIR = \"transcripts\"\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSCRIPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_livestream(video_id):\n",
    "    \"\"\"Checks if a video is a livestream using yt-dlp metadata.\"\"\"\n",
    "    url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'simulate': True,\n",
    "        'force_generic_extractor': False,\n",
    "        'no_warnings': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)  # Get metadata without downloading\n",
    "\n",
    "    # Check if the video is a livestream\n",
    "    return info.get(\"is_live\", False)\n",
    "\n",
    "def download_audio(video_id, output_format=\"mp3\", failed_videos=None):\n",
    "    \"\"\"Downloads audio from a YouTube video and saves it in the audio directory.\"\"\"\n",
    "    \n",
    "    if failed_videos is None:\n",
    "        failed_videos = []  # Prevents NoneType issues\n",
    "\n",
    "    # **Check if the video is a livestream**\n",
    "    if is_livestream(video_id):\n",
    "        print(f\"⚠️ Skipping {video_id}: It is a livestream.\")\n",
    "        failed_videos.append(video_id)  # Add to failed list\n",
    "        return None  # Prevent downloading\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        output_filename = os.path.join(AUDIO_DIR, f\"{video_id}.%(ext)s\")  # Save in AUDIO_DIR\n",
    "\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': output_filename,\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': output_format,\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "\n",
    "        # Check for incorrect double extension\n",
    "        expected_filename = os.path.join(AUDIO_DIR, f\"{video_id}.{output_format}\")\n",
    "        double_extension = os.path.join(AUDIO_DIR, f\"{video_id}.{output_format}.{output_format}\")\n",
    "\n",
    "        if os.path.exists(double_extension):\n",
    "            os.rename(double_extension, expected_filename)\n",
    "\n",
    "        return expected_filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio for video {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "    model = whisper.load_model(\"base\", device=device)  # Load Whisper on GPU with base model\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def save_transcript(video_id, transcript_text):\n",
    "    output_filename = os.path.join(TRANSCRIPT_DIR, f\"{video_id}.txt\")\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(transcript_text)\n",
    "    print(f\"Transcript saved at: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=UI0Hgxan_LE\n",
      "[youtube] UI0Hgxan_LE: Downloading webpage\n",
      "[youtube] UI0Hgxan_LE: Downloading tv client config\n",
      "[youtube] UI0Hgxan_LE: Downloading player af7f576f\n",
      "[youtube] UI0Hgxan_LE: Downloading tv player API JSON\n",
      "[youtube] UI0Hgxan_LE: Downloading ios player API JSON\n",
      "[youtube] UI0Hgxan_LE: Downloading m3u8 information\n",
      "[info] UI0Hgxan_LE: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_files\\UI0Hgxan_LE.webm\n",
      "[download] 100% of    7.20MiB in 00:00:00 at 8.14MiB/s   \n",
      "[ExtractAudio] Destination: audio_files\\UI0Hgxan_LE.mp3\n",
      "Deleting original file audio_files\\UI0Hgxan_LE.webm (pass -k to keep)\n",
      "File exists: audio_files\\UI0Hgxan_LE.mp3\n",
      "Transcript saved at: transcripts\\UI0Hgxan_LE.txt\n"
     ]
    }
   ],
   "source": [
    "video_id = \"UI0Hgxan_LE\"\n",
    "\n",
    "# Step 1: Download Audio\n",
    "audio_file = download_audio(video_id)\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(audio_file):\n",
    "    print(f\"File exists: {audio_file}\")\n",
    "else:\n",
    "    print(f\"File not found: {audio_file}\")\n",
    "\n",
    "# Step 2: Transcribe Audio\n",
    "transcript = transcribe_audio(audio_file)\n",
    "\n",
    "# Step 3: Save Transcript\n",
    "save_transcript(video_id, transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"transcriptless_videos_1.csv\") # Replace with your CSV file\n",
    "\n",
    "failed_videoes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    video_id = row[\"Video Id\"]  # Extract Video ID\n",
    "    print(f\"\\nProcessing Video ID: {video_id}\")\n",
    "\n",
    "    audio_file = download_audio(video_id, failed_videos=failed_videoes)\n",
    "\n",
    "    if audio_file is None:\n",
    "        print(f\"Skipping {video_id}: Download failed.\")\n",
    "        continue  # Skip to the next video\n",
    "\n",
    "    if os.path.exists(audio_file):\n",
    "        print(f\"File exists: {audio_file}\")\n",
    "        try:\n",
    "            transcript = transcribe_audio(audio_file)\n",
    "            save_transcript(video_id, transcript)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during transcription for {video_id}: {e}\")\n",
    "            failed_videoes.append(video_id)\n",
    "    else:\n",
    "        print(f\"Error: Audio file {audio_file} not found! Skipping.\")\n",
    "        failed_videoes.append(video_id)\n",
    "\n",
    "\n",
    "if failed_videoes:\n",
    "    print(\"\\n⚠️ The following videos failed to generate transcripts:\")\n",
    "    for vid in failed_videoes:\n",
    "        print(f\"- {vid}\")\n",
    "else:\n",
    "    print(\"\\n✅ All videos were successfully processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
